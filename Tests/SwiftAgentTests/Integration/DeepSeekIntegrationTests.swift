//
//  DeepSeekIntegrationTests.swift
//  SwiftAgentTests
//
//  DeepSeek API é›†æˆæµ‹è¯•
//

import XCTest
@testable import SwiftAgent

final class DeepSeekIntegrationTests: XCTestCase {
    var provider: DeepSeekProvider!
    var apiKey: String!
    
    override func setUp() async throws {
        // ä»ç¯å¢ƒå˜é‡è·å– API Key
        apiKey = ProcessInfo.processInfo.environment["DEEPSEEK_API_KEY"]
        
        // å¦‚æœæ²¡æœ‰ API Keyï¼Œè·³è¿‡æµ‹è¯•
        guard apiKey != nil && !apiKey.isEmpty else {
            throw XCTSkip("DEEPSEEK_API_KEY environment variable not set")
        }
        
        provider = DeepSeekProvider(apiKey: apiKey, model: .chat)
    }
    
    // MARK: - åŸºç¡€å¯¹è¯æµ‹è¯•
    
    func testBasicChat() async throws {
        // Given
        let messages = [
            LLMMessage(role: .user, content: "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")
        ]
        
        // When
        let response = try await provider.chat(messages: messages, tools: nil, temperature: 0.7)
        
        // Then
        XCTAssertFalse(response.content.isEmpty, "å“åº”å†…å®¹ä¸åº”ä¸ºç©º")
        XCTAssertNotNil(response.usage, "åº”è¯¥è¿”å›tokenä½¿ç”¨ç»Ÿè®¡")
        print("âœ… åŸºç¡€å¯¹è¯æµ‹è¯•é€šè¿‡")
        print("ğŸ“ å“åº”: \(response.content)")
        print("ğŸ“Š Tokenä½¿ç”¨: \(response.usage?.totalTokens ?? 0)")
    }
    
    func testMultiTurnConversation() async throws {
        // Given
        let messages = [
            LLMMessage(role: .user, content: "æˆ‘æƒ³äº†è§£Swiftç¼–ç¨‹è¯­è¨€"),
            LLMMessage(role: .assistant, content: "Swiftæ˜¯Appleå¼€å‘çš„ç°ä»£ç¼–ç¨‹è¯­è¨€ï¼Œç”¨äºiOSã€macOSç­‰å¹³å°å¼€å‘ã€‚"),
            LLMMessage(role: .user, content: "å®ƒæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿè¯·åˆ—ä¸¾3ç‚¹ã€‚")
        ]
        
        // When
        let response = try await provider.chat(messages: messages, tools: nil, temperature: 0.7)
        
        // Then
        XCTAssertFalse(response.content.isEmpty)
        XCTAssertTrue(response.content.contains("1") || response.content.contains("ä¸€"), "åº”è¯¥åŒ…å«åˆ—ä¸¾å†…å®¹")
        print("âœ… å¤šè½®å¯¹è¯æµ‹è¯•é€šè¿‡")
        print("ğŸ“ å“åº”: \(response.content)")
    }
    
    // MARK: - æµå¼å“åº”æµ‹è¯•
    
    func testStreamingChat() async throws {
        // Given
        let messages = [
            LLMMessage(role: .user, content: "è¯·å†™ä¸€ä¸ªç®€çŸ­çš„æ•…äº‹ï¼ˆ50å­—ä»¥å†…ï¼‰")
        ]
        
        var receivedChunks: [String] = []
        var fullContent = ""
        
        // When
        let response = try await provider.chatStream(
            messages: messages,
            tools: nil,
            temperature: 0.7
        ) { chunk in
            receivedChunks.append(chunk)
            fullContent += chunk
        }
        
        // Then
        XCTAssertFalse(receivedChunks.isEmpty, "åº”è¯¥æ”¶åˆ°æµå¼æ•°æ®å—")
        XCTAssertFalse(fullContent.isEmpty, "æµå¼å†…å®¹ä¸åº”ä¸ºç©º")
        XCTAssertEqual(response.content, fullContent, "æœ€ç»ˆå“åº”åº”è¯¥ä¸æµå¼å†…å®¹ä¸€è‡´")
        print("âœ… æµå¼å“åº”æµ‹è¯•é€šè¿‡")
        print("ğŸ“Š æ”¶åˆ° \(receivedChunks.count) ä¸ªæ•°æ®å—")
        print("ğŸ“ å®Œæ•´å†…å®¹: \(fullContent)")
    }
    
    func testStreamingWithAgent() async throws {
        // Given
        let agent = Agent(name: "StreamingAgent", llmProvider: provider, systemPrompt: "ä½ æ˜¯ä¸€ä¸ªhelpfulçš„AIåŠ©æ‰‹")
        var chunks: [String] = []
        
        // When
        let callback = StreamingCallback(
            onContent: { content in
                chunks.append(content)
                print(content, terminator: "")
            },
            onToolCall: { toolCall in
                print("\nğŸ”§ å·¥å…·è°ƒç”¨: \(toolCall.name ?? "unknown")")
            },
            onCompletion: { response in
                print("\nâœ… å®Œæˆ: \(response.finishReason ?? "unknown")")
            },
            onError: { error in
                print("\nâŒ é”™è¯¯: \(error.localizedDescription)")
            }
        )
        
        let response = try await agent.streamRunWithCallback(
            input: "è¯·è¯´ä¸€å¥é¼“åŠ±çš„è¯",
            callback: callback
        )
        
        // Then
        XCTAssertFalse(chunks.isEmpty)
        XCTAssertFalse(response.content.isEmpty)
        print("\nâœ… Agentæµå¼æµ‹è¯•é€šè¿‡")
    }
    
    // MARK: - å·¥å…·è°ƒç”¨æµ‹è¯•
    
    func testToolCalling() async throws {
        // Given
        let tools = [
            LLMToolFunction(
                name: "get_weather",
                description: "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
                parameters: [
                    "type": AnyCodable("object"),
                    "properties": AnyCodable([
                        "city": [
                            "type": "string",
                            "description": "åŸå¸‚åç§°ï¼Œå¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·"
                        ]
                    ]),
                    "required": AnyCodable(["city"])
                ]
            )
        ]
        
        let messages = [
            LLMMessage(role: .user, content: "ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
        ]
        
        // When
        let response = try await provider.chat(messages: messages, tools: tools, temperature: 0.7)
        
        // Then
        if let toolCalls = response.toolCalls, !toolCalls.isEmpty {
            XCTAssertEqual(toolCalls.first?.function.name, "get_weather")
            print("âœ… å·¥å…·è°ƒç”¨æµ‹è¯•é€šè¿‡")
            print("ğŸ”§ è°ƒç”¨å·¥å…·: \(toolCalls.first?.function.name ?? "")")
            print("ğŸ“ å‚æ•°: \(toolCalls.first?.function.arguments ?? "")")
        } else {
            print("âš ï¸ æ¨¡å‹æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œå¯èƒ½ç›´æ¥å›ç­”äº†é—®é¢˜")
            print("ğŸ“ å“åº”: \(response.content)")
        }
    }
    
    // MARK: - Agent å®Œæ•´æµ‹è¯•
    
    func testAgentWithDeepSeek() async throws {
        // Given
        let agent = Agent(name: "DeepSeekAgent", llmProvider: provider, systemPrompt: "ä½ æ˜¯ä¸€ä¸ªhelpfulçš„AIåŠ©æ‰‹")
        await agent.registerBasicTools()
        
        // When
        let response = try await agent.run("ä½ å¥½ï¼Œè¯·å‘Šè¯‰æˆ‘ç°åœ¨çš„æ—¶é—´")
        
        // Then
        XCTAssertFalse(response.isEmpty)
        print("âœ… Agentå®Œæ•´æµ‹è¯•é€šè¿‡")
        print("ğŸ“ å“åº”: \(response)")
    }
    
    // MARK: - ä¸åŒæ¨¡å‹æµ‹è¯•
    
    func testChatModel() async throws {
        // Given
        let chatProvider = DeepSeekProvider(apiKey: apiKey, model: .chat)
        let messages = [LLMMessage(role: .user, content: "ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹ï¼Ÿ")]
        
        // When
        let response = try await chatProvider.chat(messages: messages, tools: nil, temperature: 0.7)
        
        // Then
        XCTAssertFalse(response.content.isEmpty)
        print("âœ… Chatæ¨¡å‹æµ‹è¯•é€šè¿‡")
        print("ğŸ“ å“åº”: \(response.content)")
    }
    
    func testCoderModel() async throws {
        // Given
        let coderProvider = DeepSeekProvider(apiKey: apiKey, model: .coder)
        let messages = [LLMMessage(role: .user, content: "å†™ä¸€ä¸ªSwiftå‡½æ•°è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—")]
        
        // When
        let response = try await coderProvider.chat(messages: messages, tools: nil, temperature: 0.7)
        
        // Then
        XCTAssertFalse(response.content.isEmpty)
        XCTAssertTrue(response.content.contains("func") || response.content.contains("swift"), "åº”è¯¥åŒ…å«ä»£ç ")
        print("âœ… Coderæ¨¡å‹æµ‹è¯•é€šè¿‡")
        print("ğŸ“ å“åº”: \(response.content)")
    }
    
    // MARK: - é”™è¯¯å¤„ç†æµ‹è¯•
    
    func testInvalidAPIKey() async throws {
        // Given
        let invalidProvider = DeepSeekProvider(apiKey: "invalid_key", model: .chat)
        let messages = [LLMMessage(role: .user, content: "test")]
        
        // When/Then
        do {
            _ = try await invalidProvider.chat(messages: messages, tools: nil, temperature: 0.7)
            XCTFail("åº”è¯¥æŠ›å‡ºé”™è¯¯")
        } catch {
            print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡: \(error.localizedDescription)")
        }
    }
    
    // MARK: - æ€§èƒ½æµ‹è¯•
    
    func testResponseTime() async throws {
        // Given
        let messages = [LLMMessage(role: .user, content: "ä½ å¥½")]
        let startTime = Date()
        
        // When
        let response = try await provider.chat(messages: messages, tools: nil, temperature: 0.7)
        let endTime = Date()
        let duration = endTime.timeIntervalSince(startTime)
        
        // Then
        XCTAssertFalse(response.content.isEmpty)
        print("âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡")
        print("â±ï¸ å“åº”æ—¶é—´: \(String(format: "%.2f", duration))ç§’")
        print("ğŸ“Š Tokenä½¿ç”¨: \(response.usage?.totalTokens ?? 0)")
    }
}

